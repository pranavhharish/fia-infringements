{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Infringement Analysis - Exploratory Notebook\n",
    "\n",
    "This notebook provides an interactive exploration of the F1 infringement analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Add src to path\u001b[39;00m\n\u001b[32m      9\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(Path.cwd().parent / \u001b[33m'\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_processing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_extractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFExtractor\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mteam_detector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TeamDetector\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mentity_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentity_extractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EntityExtractor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MSIM-24-26/MSIM-FALL-25/Textmining/project/Textmining_Project/Pranavh/src/data_processing/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Data processing modules\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_extractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFExtractor\n\u001b[32m      5\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mPDFExtractor\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MSIM-24-26/MSIM-FALL-25/Textmining/project/Textmining_Project/Pranavh/src/data_processing/pdf_extractor.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Dict\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyPDF2\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPDFExtractor\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from data_processing.pdf_extractor import PDFExtractor\n",
    "from utils.team_detector import TeamDetector\n",
    "from entity_extraction.entity_extractor import EntityExtractor\n",
    "from summarization.extractive_summarizer import ExtractiveSummarizer\n",
    "from summarization.team_summarizer import TeamYearSummarizer\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed results\n",
    "records_df = pd.read_csv('../outputs/infringement_records.csv')\n",
    "summaries_df = pd.read_csv('../outputs/team_year_summaries.csv')\n",
    "\n",
    "print(f\"Total records: {len(records_df)}\")\n",
    "print(f\"Total summaries: {len(summaries_df)}\")\n",
    "\n",
    "records_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infractions by year\n",
    "plt.figure(figsize=(12, 6))\n",
    "records_df['year'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Infractions by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Infractions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infractions by team\n",
    "plt.figure(figsize=(14, 6))\n",
    "records_df['team'].value_counts().plot(kind='barh')\n",
    "plt.title('Infractions by Team (2020-2024)')\n",
    "plt.xlabel('Number of Infractions')\n",
    "plt.ylabel('Team')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common infraction types\n",
    "plt.figure(figsize=(12, 6))\n",
    "records_df['primary_infraction'].value_counts().head(10).plot(kind='barh')\n",
    "plt.title('Top 10 Infraction Types')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Infraction Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalty type distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "records_df['penalty_type'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Penalty Type Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Team-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a team to analyze\n",
    "team_name = 'Mercedes'  # Change this to analyze different teams\n",
    "\n",
    "team_data = records_df[records_df['team'] == team_name]\n",
    "print(f\"\\n{team_name} Analysis:\")\n",
    "print(f\"Total infractions: {len(team_data)}\")\n",
    "print(f\"\\nYearly breakdown:\")\n",
    "print(team_data['year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team infraction trends over years\n",
    "team_yearly = records_df[records_df['team'] == team_name].groupby('year').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "team_yearly.plot(kind='line', marker='o')\n",
    "plt.title(f'{team_name} Infractions Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Infractions')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Individual Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PDF extraction on a sample file\n",
    "sample_pdf = Path('../../Documents/2023-infridgement_profile').glob('*.pdf').__next__()\n",
    "\n",
    "extractor = PDFExtractor()\n",
    "text = extractor.extract_text_from_pdf(sample_pdf)\n",
    "cleaned_text = extractor.clean_text(text)\n",
    "\n",
    "print(f\"Extracted text length: {len(cleaned_text)} characters\")\n",
    "print(f\"\\nFirst 500 characters:\\n{cleaned_text[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test team detection\n",
    "detector = TeamDetector('../config/team_mappings.json')\n",
    "team_result = detector.detect_team(text, '2023')\n",
    "\n",
    "if team_result:\n",
    "    team_name, confidence = team_result\n",
    "    print(f\"Detected team: {team_name}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "else:\n",
    "    print(\"No team detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test entity extraction\n",
    "entity_extractor = EntityExtractor()\n",
    "entities = entity_extractor.extract_all_entities(cleaned_text, team_name)\n",
    "\n",
    "print(\"Extracted entities:\")\n",
    "print(json.dumps(entities, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extractive summarization\n",
    "summarizer = ExtractiveSummarizer(method='lexrank', num_sentences=3)\n",
    "summary = summarizer.summarize(cleaned_text)\n",
    "\n",
    "print(\"Extractive Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Custom Team Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate team-year summary\n",
    "team_summarizer = TeamYearSummarizer()\n",
    "\n",
    "# Convert dataframe to records\n",
    "records = records_df.to_dict('records')\n",
    "\n",
    "# Generate summary for specific team-year\n",
    "summary = team_summarizer.generate_team_year_summary(\n",
    "    records,\n",
    "    team='Mercedes',\n",
    "    year='2023',\n",
    "    style='factual',\n",
    "    num_insights=5\n",
    ")\n",
    "\n",
    "if summary:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{summary['team']} - {summary['year']}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    for insight in summary['insights']:\n",
    "        print(f\"• {insight}\")\n",
    "else:\n",
    "    print(\"No summary generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization: Heatmap of Team Infractions by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table\n",
    "pivot = records_df.pivot_table(\n",
    "    index='team',\n",
    "    columns='year',\n",
    "    values='filename',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pivot, annot=True, fmt='d', cmap='YlOrRd')\n",
    "plt.title('Team Infractions Heatmap (2020-2024)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Team')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Custom Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom summary report\n",
    "output_path = '../outputs/custom_analysis.txt'\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(\"F1 INFRINGEMENT ANALYSIS - CUSTOM REPORT\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    # Overall stats\n",
    "    f.write(f\"Total Documents: {len(records_df)}\\n\")\n",
    "    f.write(f\"Years Covered: {', '.join(map(str, sorted(records_df['year'].unique())))}\\n\")\n",
    "    f.write(f\"Teams: {len(records_df['team'].unique())}\\n\\n\")\n",
    "    \n",
    "    # Top infractions\n",
    "    f.write(\"Top 5 Infraction Types:\\n\")\n",
    "    for i, (infraction, count) in enumerate(records_df['primary_infraction'].value_counts().head(5).items(), 1):\n",
    "        f.write(f\"{i}. {infraction}: {count}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(f\"Custom report saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides an interactive way to explore the F1 infringement data and test the analysis pipeline components. Modify the cells above to customize your analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
